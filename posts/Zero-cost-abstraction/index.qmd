---
title: "Zero Cost Abstraction"
author: "Sanjeevi "
date: "2022-12-31"
categories: [Theory]
image: "image.jpg"
---
Zero cost abstraction is a memory model for the system programming language that provides abstraction equivalent to handwritten low-level code without any additional overhead, proposed by Stroustrup in his paper Abstraction and C++ machine model. Let's decompose them to explain their properties.

**Zero**:

>What you do use, you couldn't hand code any better.

 It's still costly but compared to other high-level languages(Python, Java, C#) they have little overhead when using virtual dispatch. Once the c/c++ compiler emits the assembly from the source code through _GCC or LLVM_ the compiler is no longer needed which means we can distribute executable files without the end user installing c/c++.Whereas in dynamic programming languages the source code and the language runtime must always sit behind to run the program. Just because we have lots of memory that doesn't mean use all of that, that's what garbage collectors do. Whereas in embedded systems memory is measured in KiloBytes rather than GigaBytes, TeraBytes in PC, supercomputers in that GC is not an option other than using c/c++ or now rust. It's fast as the hardware allowed.

**Cost**:

>What you don't use, you don't pay for.

 Every computation we perform has a cost associated with it, and how many resources(time and space) are needed to run a particular kind of task? Garbage-collected languages take more memory than necessary than manual memory management languages like c,c++, and rust.

 **Abstraction** :

 - Modularity: Large code bases must be organized to reason about, and reused later. Adding new features doesn't affect the rest of the code base. Aid in good API design. 
 It's not always possible to provide abstraction for all kinds of tasks. For eg Linux kernel uses a little bit of assembly in it, which is hard to abstract but uses assembly.

 - Less code maintenance. Rust features include Enums to write your intention compactly, Derive Macros to generate boilerplate code at compile time, and Generics to reduce the code lines but also the safety checking along the way.

 - Python and Js provide the highest level of abstraction which hides lots of complexity like Pointers, and Dynamic Memory allocation thus lacking control over hardware and instead preferring the ease of use, learning, and prototyping over runtime performance.

 - Exposing low-level details to the end user would mess up the hardware resources if they were using it inappropriately. For example at a low level, the alignment of the bit must be multiple by the size of the data type and power of two. If we design an API in a way that refuses to compile if violating the requirements. In this way abstraction provides security. The same is true for kernels, CUDA, and Operations on a type.

- Source Level compatibility and portability(API)-Standard libraries(C++ templates, iterators) use an os specific libraries to implement functionality like a filesystem, and networks but at the source level they are identical APIs but under the hood (conditional compilation) they are different. This makes code portable, and less maintenance, No need to learn new APIs for each platform except for architecture-specific features.

- Least level of abstraction provided by Assembly. 

## Other languages that are used in embedded systems:

[Ada](https://www.adacore.com/about-spark)
[D](https://dlang.org/)
[Ivory](https://ivorylang.org)

## CPU Chip Architecture
 Each CPU architecture has different assembly instructions, some are backward compatible others don't. The compiler is a complex piece of software that does the heavy work of converting high-level concepts to architecture-specific assembly. Below are the most used CPU architectures and their 32 and 64-bit variants.

 - Intel
 - AMD
 - Arm
 - PowerPC(IBM)
 - Alpha
 - Apple Silicon(Only available in Apple products)
 - Risc -v(Opensource Instruction Set Architecture(ISA)))

 It's misleading when people say c++ is platform-dependent, but java has a famous quote that
"Write once, run anywhere".A lot of the complexity is abstracted away from the programmer by the java runtime libraries.Java Runtime converts platform-independent byte code into machine-specific instruction at runtime.


If Manual memory management is more efficient then why do we have GCed language in the first place? The software runs the world, it is important to write software that is memory-safe since writing memory-safety software in a system programming language leads to vulnerability because of the way the language is designed. Lots of series vulnerabilities are found in c/c++ code bases.GCed language prefers safety over runtime performance. But **rust** came to break that tradeoff as we will see in the next article. 

# Pros of managed or GCed language
No need to worry about memory-related bugs at runtime(though not all bugs are addressed by GC). Instead, focus on the problem you want to solve rather than weird problems.

# Pros of Manual Memory Management
Predictable performance of memory allocation and deallocation thus efficient use of resources.
 
A program's performance can be improved if most of the bugs are moved to compile time rather than runtime. For example *safe* **rust** refuse to compile if the program has a dangling pointer.

I hope you understand the reason why c/c++ is used to write operating systems, kernels, boot loaders, networking, file systems, database, and many low-level kinds of stuff that get the most out of available hardware without imposing any additional overhead even though they are unsafe.

## References
 - <a href="https://blog.rust-lang.org/2015/05/11/traits.html" target="_blank">Zero cost abstraction in Rust blog</a> 
- <a href="https://link.springer.com/chapter/10.1007/11535409_1" target="_blank">Abstraction and C++ machine model stroustrup 2005</a>